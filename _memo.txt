#-------------------------------------------------------------------------------
データサイエンス100本ノック（構造化データ加工編）
https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess

データサイエンス100本ノック～構造化データ加工編ガイドブック
https://amzn.to/3Pmq47H

#-------------------------------------------------------------------------------
* ChatGPT
* 次のコードはもっとエレガントに書けない？

使用する関数やテクニック:（JOIN、CASE、LAG、group_by() など）
難易度:（初心者向け、中級者向け、実務レベル）

#-------------------------------------------------------------------------------
* github を2つのアカウントで運用する. 

サイトタイトル：
katsu データサイエンスラボ

https://katsu-ds-lab.com
katsu-ds-lab
@katsu_ds_lab
katsu.ds.lab@gmail.com

将来的に法人化を考える際、以下は適切？
サイトタイトル：
Katsu Data Science Lab
URL: 
https://katsu-ds-lab.com/

Katsu Data Science
Katsu Analytics

* ブログタイトル

サイト名: 
katsu データサイエンスラボ

サブタイトル: 
R と SQL で学ぶ、データ活用の実践スキル
Real-World Data Mastery with R & SQL
# Real-World Data Skills with R & SQL

**「Katsu Data Science Lab」向けのサブタイトル候補（日本語 & 英語）**  

0. 現場で役立つデータの世界🌐 R と SQL で学ぶ実践スキル
1. **データで世界を解き明かす、実践型ラボ**  
2. **現場で役立つデータサイエンスを学ぶ**  
3. **RとSQLでデータ活用力を鍛える**  
4. **データサイエンスの実践力を高めるラボ**  
5. **データの力を引き出す、学びと実践の場**  
6. **現場で使えるデータサイエンススキルを習得**  
7. **実データで学ぶ、実践的データサイエンス**  
8. **データサイエンス × 実務力の強化ラボ**  

1. **Unlocking Insights with Real-World Data Science**  
2. **Practical Data Science for the Real World**  
3. **Mastering Data Science with R & SQL**  
4. **Hands-on Learning for Data-Driven Success**  
5. **From Data to Decisions: Learn, Apply, Succeed**  
6. **Empowering You with Practical Data Skills**  
7. **The Lab for Real-World Data Science Mastery**  
8. **Where Data Science Meets Practical Application**  

### **💡 選び方のポイント**  
- **ターゲットに合わせる**  
　→ **初心者向け**なら「学ぶ」「習得」といった表現  
　→ **実務者向け**なら「実践」「応用」「現場で役立つ」などの表現  
- **サイトのコンセプトに沿う**  
　→ RとSQLに特化するなら、それを明記するのもあり  
　→ データ活用の総合力を重視するなら「意思決定」「活用」「応用」などのキーワードを入れる  

気になる候補があれば、さらに調整できます！

katsu データサイエンスラボ
katsu データサイエンス・ラボ
katsu DS実践ラボ
katsu DSラボ
Katsu Data Science Lab
Katsu データサイエンス Lab
Katsu データサイエンス実践ラボ
Katsu DS 実践ラボ（「データサイエンス」の略を使う）
Katsu DS Academy

* 演習問題タイトル

[R+SQL] データサイエンス100本ノック＋α (標準編) R-029
[R+SQL] データサイエンス実践ドリル (標準編)

[R & SQL] データサイエンス実践ドリル - 公式版
[R & SQL] データサイエンス実践ドリル - ベーシック版
[R & SQL] データサイエンス実践ドリル - マスター版
[R & SQL] Data Science Practice Drills - Official Edition
[R & SQL] Data Science Practice Drills - Basic Edition
[R & SQL] Data Science Practice Drills - Master Edition

Data Science Practice Drill

[R & SQL] データサイエンス実践ドリル - 公式版 R-029
[R & SQL] データサイエンス実践ドリル - ベーシック版 B-001
[R & SQL] データサイエンス実践ドリル - マスター版 M-012
[R & SQL] Data Science Practical Drill - Official Edition R-029
[R & SQL] Data Science Practical Drill - Basic Edition B-001
[R & SQL] Data Science Practical Drill - Master Edition M-012

参考：
[R & SQL] データサイエンス実践ドリル (データ加工編) - 公式版
[R & SQL] データサイエンス実践ドリル - オリジナル版
[R & SQL] Data Science Drill - Official Edition
[R & SQL] Data Science Drill - Basic Edition
[R & SQL] Data Science Drill - Master Edition

[R+SQL] Data Science Practical Drill - Official Edition
[R+SQL] Data Science Practical Drill - Original Edition

【無料・有料】
体験版 + 応用版
ベーシック版、マスター版

# [R+SQL] データサイエンス実践ドリル - 標準問題集
[R+SQL] データサイエンス実践ドリル - 公式問題集
[R+SQL] データサイエンス実践ドリル - オリジナル問題集
# [R+SQL] データサイエンス実践ドリル - 発展問題集

[R+SQL] データサイエンス実践ドリル - 公式問題 R-029
[R+SQL] データサイエンス実践ドリル - オリジナル問題 A-012

# [R+SQL] Data Science Practical Drill - Standard Problems
[R+SQL] Data Science Practical Drill - Official Problems
[R+SQL] Data Science Practical Drill - Original Problems
# [R+SQL] Data Science Practical Drill - Advanced Problems
[R+SQL] Data Science Practical Drill - Official Problem R-029

[R+SQL] データサイエンス実践ドリル (データ加工編) - 標準問題集
[R+SQL] データサイエンス実践ドリル (データ加工編) - 発展問題集

[R+SQL] Data Science Practical Drill (Data Processing) - Standard Problems
[R+SQL] Data Science Practical Drill (Data Processing) - Advanced Problems
[R+SQL] Data Science Practical Drill (Data Processing) - Standard Problem R-029

データサイエンス実践問題集
データサイエンス実践ドリル

Data Science Practice Drills

体系的に学びながら問題を解きたい場合は、「データサイエンス実践問題集」が適切です。
反復練習や実践的なスキル向上を重視した内容であれば、「データサイエンス実践ドリル」の方がより適切です。
体系的な学習を目指さず、特定の技術やスキルを実際に練習するための問題集という印象を持たせるために「ドリル」を使うのが良いでしょう。

データサイエンス実践ドリル | Practical Data Science Drills
データサイエンス実践問題集 | Data Science Practice Drills
データサイエンスチャレンジ＋α | Data Science Challenge + Extra

Data Science Drill Book
Data Science Exercises for Practice
Data Science Challenges & Drills

【R+SQL】データサイエンス100本ノック＋αでスキルアップ - 標準編
【R+SQL】データサイエンス100本ノック＋αでスキルアップ - 発展編

【R+SQL】データサイエンス100本ノック＋α - 標準編
【R+SQL】データサイエンス100本ノック＋α - 発展編
【R+SQL】データサイエンス100本ノック＋α - 標準編 R-028
【R+SQL】データサイエンス100本ノック＋α - 発展編 A-001

標準編: Standard Edition
上級編、発展編: Advanced Edition

# 公式編, 発展編
# 標準編, スタンダード編, 基本編, ベーシック編, 練習編
# 応用編, アドバンス編, オリジナル編, 実践編, 挑戦編, チャレンジ編
# R初心者から中級者へ：100本ノック＋αでスキルアップ
# データサイエンス100本ノックから学ぶ実践テクニック

概要: overview
Introduction: 「紹介」や「導入」「序論」とい
要旨: abstract
要約: summary
説明: Description.
setup: 設定、準備、セットアップ
開始: init
Tips: (ヒント)
「小技」「豆知識」「ハウツー」などのニュアンスが近いです。
ちょっとしたコツや役に立つ情報、知識の断片を指す英単語です。特定の作業や問題解決を効率よく行うための実用的なアドバイスや知識を簡潔に伝える場面で使われます。

* オススメのテーマ
Geekdoc は、デフォルトでコードブロック内の指定行をハイライトする機能がある。
LoveIt, Coder, Docsy

* categories

100本ノック+α (基本情報)
R+SQL(基本情報)
R+SQL(演習問題)
レビュー

100本ノック+α(基本情報)
100本ノック+α(標準編)
100本ノック+α(発展編)
100本ノック+α(難易度1)
...
100本ノック+α(難易度5)
100本ノック+α(⭐️1)

* tags:

R
SQL
CASE式
日付処理
文字列処理
欠損値処理
データ型変換
カテゴリ変換
乱数
統計量
(最頻値を含む)
外れ値・異常値
重複データ処理
グループ化
パターンマッチング
フィルタリング
集約関数
ランキング関数
シフト関数
累積関数
ウィンドウ関数
縦横変換
集合演算
データ結合
サンプリング
データ分割
(数値データをカテゴリに変換する場合など)
正規化
全組み合わせ
(デカルト積)
データ補完
名寄せ

数値丸め
(四捨五入演算)
データ上書き
不均衡データ
データクレンジング
非正規化
標準化
サブクエリ
(副問合せ)
CTE
(共通テーブル式)
ファイル入出力
書籍レビュー

* カスタムドメイン, https, katsu-ds-lab.com

* アフィリエイトリンク: 

アフィリエイト: 
国内
Amazon, Yahoo, 楽天、Google AdSense
国外
Amazon

* Google キーワードプランナー (検索ボリューム)

* Google Analytics

* Google Search Console

* SQLite
Date型やDatetime型が無い.

* テスト環境: 

cd /Users/kk/ds/
git clone https://github.com/katsu-ds-lab/ds-drills.git
cd ds-drills
# git pull origin main

setwd("/Users/kk/ds/ds-drills/work")

* ソース公開向けGithubリポジトリ: 
git@github.com:katsu-ds-lab/ds-drills.git

* コーディング,リライト
なるべくエレガントで拡張性の高いコード
duckdb を使用.
receipt.sales_ymd を integer に変更する
変数と関数名をスネークケースにする
列名を修正する

# R-029 ------------
# [R] データフレームでの処理
# [R] データベース・バックエンドでの処理
# SQLクエリ
# リライト

* メソッド一覧

# group_by(.data, ..., .add = FALSE, .drop = group_by_drop_default(.data))
# d1 %>% group_by(grp, class) %>% mutate(m = mean(x)) %>% select(group_cols(), m)
# d1 %>% relocate(1:2, .after = last_col())
# mutate(.data, ..., .by = NULL, .keep = c("all", "used", "unused", "none"),
#   .before = NULL, .after = NULL)
# filter(.data, ..., .by = NULL, .preserve = FALSE)
# summarize(.data, ..., .by = NULL, .groups = NULL)
# arrange(.data, ..., .by_group = FALSE)
# count(x, ..., wt = NULL, sort = FALSE, name = NULL)
# add_count(x, ..., wt = NULL, sort = FALSE, name = NULL)
# distinct(.data, ..., .keep_all = FALSE)

# all_of, any_of, one_of
# vars = c("customer_name", "postal_cd")
# across
# pick
# 
# select の列名変更、一般化した順序
# .before, .after
# relocate
# rename
# rename_with(.data, .fn, .cols = everything(), ...)
# group_cols(): group_by(grp, class) %>% select(group_cols())
# 
# group_by: across(vars), .add
# 
# mutate: .keep, .after, .before
# 
# reframe
# 
# {{ vars }}: 処理の共通化など
# %in% (+ subquery): d1 %>% filter(sql("class IN (SELECT DISTINCT(class) FROM tab2)"))
# if_all, if_any (filter)
# arrange : .by_group = T
# 
# count(wt, sort) を使用する設問
# add_count
# tally
# 
# summarise: 
# .groups
# across(starts_with("Sepal"), list(mean = mean, sd = sd))
# 
# complete.cases()
# slice_min
# slice_max は 042 のみ
# slice_head
# slice_sample
# dense_rank, ntile
# dense_rank, percent_rank
# 
# window_frame, window_order
# 
# order_by
# cumsum, cumall, cumany, cummean
# 
# replace_na
# pivot_longer, pivot_wider の複雑系
# 
# intersect
# union
# union_all
# setdiff
# symdiff
# 
# semi_join, anti_join
# 
# complete()
# expand()
# nesting(), crossing()
# expand_grid(), expand.grid()
# 
# クロス集計
# 
# fill
# 
# rows_insert
# rows_append
# rows_update
# rows_patch
# rows_upsert
# (rows_delete)
# 
# uncount

# RFM分析, # デシル分析, ABC分析

# count(wt, sort) を使用する設問
# 可読性の観点から考えると、count()の方が若干効率的かもしれません。
# count()はグループ化と集計を一度に行い、コードがシンプルで直感的です。
# tbl_receipt %>% 
#   summarise(sum = sum(amount), .by = c(store_cd, product_cd))
# tbl_receipt %>% 
#   count(store_cd, product_cd, wt = amount, name = "sum")

# stringr のメソッド
# str_replace など

#-------------------------------------------------------------------------------
* リダイレクトを設定して、新しい有料ドメインへのアクセスを促すこと

はい、通常はリダイレクトを設定して、新しい有料ドメインへのアクセスを促すことが一般的です。これにより、ユーザーが古いURLにアクセスしたときに自動的に新しいURLに転送されるようになります。こうすることで、訪問者は古いURLをブックマークしていても、新しい有料ドメインにスムーズに誘導できます。

GitHub Pagesの場合、リダイレクトを設定する方法としては、以下のような方法があります：

### 方法 1: `.htaccess` を使う（GitHub Pagesはサーバー側での設定を直接変更できませんが、外部サーバーの場合）

GitHub Pagesでは `.htaccess` を直接設定することはできませんが、もし外部ホスティングサービスを利用している場合は、`.htaccess` ファイルを使ってリダイレクトを設定することができます。例としては、次のような設定です。

```plaintext
Redirect 301 / https://new-custom-domain.com/
```

### 方法 2: GitHub Pagesの`CNAME`ファイルを活用する

GitHub Pagesでリダイレクトの設定を行いたい場合、通常は`CNAME`ファイルを使います。カスタムドメインを設定すると、`CNAME`ファイルに新しいドメイン名が記述され、GitHub Pagesはそのドメインを利用します。

ただし、GitHub Pagesでリダイレクト自体は直接設定できないため、リダイレクトを行いたい場合は、外部のリダイレクトサービスを使用することも考えられます。

### 方法 3: JavaScriptでリダイレクトを設定する

もし、GitHub Pagesのページでリダイレクトを行いたい場合、JavaScriptを使って簡単に設定することもできます。例えば、`index.html`に以下のスクリプトを追加することで、古いURLから新しいURLへのリダイレクトを実現できます。

```html
<script type="text/javascript">
  window.location.href = "https://new-custom-domain.com";
</script>
```

このコードを`index.html`ファイルに追加することで、ページが読み込まれるとすぐに新しいURLに自動的に転送されます。

### 結論

基本的には、リダイレクトを設定することで、訪問者が古いURLにアクセスしても、新しい有料ドメインにスムーズに誘導することができます。GitHub Pagesで直接リダイレクトを設定するのは難しいですが、JavaScriptや外部サービスを使う方法があります。

#-------------------------------------------------------------------------------
* 自動生成されたSQLクエリを show_query() で確認するメリットは？

`show_query()`で自動生成されたSQLクエリを確認することには、以下のようなメリットがあります：

---

### 1. **SQLの内容を可視化できる**
`dplyr`で記述した操作がどのようなSQLクエリに変換されたかを確認できるため、意図した通りのクエリが生成されているかを確かめることができます。特に複雑なデータ操作を行った場合、生成されたSQLクエリを確認することで、ロジックが正しいかをチェックできます。

---

### 2. **デバッグが容易**
意図しない結果が出力された場合、`show_query()`を使えばクエリの内容を確認して問題の箇所を特定しやすくなります。たとえば：

- 不要なカラムが選択されている  
- フィルタ条件が期待通りでない  
- グループ化や結合が正しく行われていない  

などのエラーや不具合に気づくことができます。

---

### 3. **SQLに馴染みのある人が内容をレビューしやすい**
チーム開発やコードレビューの場面で、SQLの内容が分かるメンバーがクエリを直接確認できます。これにより、データベース側でのパフォーマンスや設計についても意見をもらいやすくなります。

---

### 4. **パフォーマンスの最適化に役立つ**
SQLクエリの効率性を確認することで、データベース側での負荷を減らす工夫ができます。  
たとえば、`show_query()`で以下を確認できます：

- 不要な`SELECT *`が発生していないか  
- 適切にインデックスが使われる形になっているか  
- ジョインやサブクエリが非効率な形になっていないか  

問題があれば、`dplyr`の記述を修正して、SQLのパフォーマンスを改善できます。

---

### 5. **SQLクエリの学習に活用できる**
SQLに詳しくない場合でも、`dplyr`のコードを記述し、それがどのようなSQLに変換されるのかを`show_query()`で確認することで、SQLの構文やロジックを学ぶ機会になります。

---

### 6. **コードとクエリの一貫性を保証**
`dplyr`のコードと実際にデータベースで実行されるSQLクエリが一致しているかを確認できます。これにより、`dplyr`の記述が適切であることを信頼できます。

---

### 7. **生成されたSQLの手動実行や再利用が可能**
生成されたSQLを確認し、必要に応じてデータベース管理ツール（例：pgAdmin、MySQL Workbench）で直接実行できます。また、SQLをコピーして他の用途に再利用することも可能です。

---

### 具体例
以下のようなコードで、SQLの中身を確認できます：

```R
library(dplyr)

# データベース接続
con <- DBI::dbConnect(RSQLite::SQLite(), ":memory:")
my_table <- tbl(con, "table_name")

# dplyrでの操作
result <- my_table %>%
  filter(column1 > 100) %>%
  select(column2, column3) %>%
  arrange(desc(column3))

# 自動生成されたSQLクエリを表示
result %>% show_query()
```

**出力例**:
```sql
SELECT column2, column3
FROM table_name
WHERE column1 > 100
ORDER BY column3 DESC
```

この出力に基づき、意図通りのクエリになっているかを確認できます。

---

**まとめ**:  
`show_query()`を使うことで、クエリの意図を確認し、エラーを防ぐだけでなく、パフォーマンス改善やSQLの学習、再利用の機会を得ることができます。これにより、RとSQLを使ったデータ分析がさらに効率的かつ効果的になります。

#-------------------------------------------------------------------------------
* githubのアカウントxxxとアカウントyyy でプログラムを開発してます。
commit や push をする度にアカウントを切り替える手間が発生しないように設定したい。

git remote add origin git@github.com:user/repo.git 
の意味?

https://qiita.com/hiroakin66/items/a1e8b36f697c5ae385cf

--
Gitのアカウントを切り替える手間を減らすためには、以下の方法で設定できます。

### 1. **SSHキーを使い分ける**
複数のGitHubアカウントを使っている場合、それぞれのアカウントに異なるSSHキーを設定し、`~/.ssh/config`で切り替える方法が有効です。

#### ステップ：
1. 各アカウント用にSSHキーを生成します。
   ```bash
   # アカウントxxx用
   ssh-keygen -t ed25519 -C "your_email_xxx@example.com" -f ~/.ssh/id_ed25519_github_xxx
   # アカウントyyy用
   ssh-keygen -t ed25519 -C "your_email_yyy@example.com" -f ~/.ssh/id_ed25519_github_yyy
   ```

2. SSH設定ファイル（`~/.ssh/config`）を編集して、リポジトリごとに使う鍵を指定します。
   ```bash
   # ~/.ssh/config
   Host github.com-xxx
     HostName github.com
     User git
     IdentityFile ~/.ssh/id_ed25519_github_xxx
     UseKeychain yes
     IdentitiesOnly yes
   
   Host github.com-xxx
     HostName github.com
     User git
     IdentityFile ~/.ssh/id_ed25519_github_yyy
     UseKeychain yes
     IdentitiesOnly yes
   ```

3. 各リポジトリのGit設定を変更します。
   ```bash
   # アカウントxxxのリポジトリで
   git remote set-url origin git@github.com-xxx:username/repo.git

   # アカウントyyyのリポジトリで
   git remote set-url origin git@github.com-yyy:username/repo.git
   ```

これで、各リポジトリに対して自動的に適切なSSHキーが使用されます。

### 2. **Gitのユーザー設定をリポジトリごとに変更**
Gitでは、リポジトリごとに異なるユーザー情報を設定することもできます。以下のコマンドを使って、リポジトリごとに異なるユーザー名とメールアドレスを設定できます。

```bash
# アカウントxxxのリポジトリで
cd cloned_project
git config --local user.name "gitのアカウント名xxx"
git config --local user.email "gitに登録しているメールアドレスxxx"
git config --local url."github.com-xxx".insteadOf "git@github.com"

# アカウントyyyのリポジトリで
cd cloned_project
git config --local user.name "gitのアカウント名yyy"
git config --local user.email "gitに登録しているメールアドレスyyy"
git config --local url."github.com-yyy".insteadOf "git@github.com"
```

これらの設定により、`commit` や `push` の際に、それぞれのアカウントの情報が反映されます。
このように、SSHキーやGitの設定を活用して、アカウントを切り替える手間を省くことができます。

#-------------------------------------------------------------------------------
* データサイエンス100本ノック (構造化データ加工編) などの書籍に掲載されてる設問を、ブログサイトに公開しても大丈夫？

1. 引用の範囲内で利用
著作権法上の「引用」の要件を満たせば、設問の一部をブログに掲載することが可能です。以下が引用の要件です：

公正な慣行に合致していること（目的や量が妥当である）。
引用部分が主従関係で「従」になっていること（引用がブログのメインではなく補足である）。
出典を明示すること（著者名・書籍名・出版社名など）。
例えば、問題文全体ではなく、キーワードや概要を簡単に記載し、その上で自分の解説や考察を中心にした内容を作ると良いでしょう。

2. 出版社や著者に確認を取る
設問を大部分そのまま利用したい場合や、問題文全体を引用したい場合は、出版社（技術評論社など）や著者に連絡して許可を得ることが推奨されます。許可を得ることで、問題なく利用できます。

3. オリジナルの表現に書き換える
設問の内容をそのまま記載せず、自分の言葉で問題の趣旨を説明し、独自の例や問題形式に書き換える方法もあります。この場合、元の設問が参考であることを明記し、リンクや書籍情報を提供することで、元の著作物への敬意を示せます。

4. 書籍のプロモーションを活用
書籍の概要や内容をブログで解説し、読者に「実際の問題を体験したい方はこの書籍を購入してください」と促す形で、アフィリエイトリンクを活用するのは効果的です。問題文を直接掲載せずとも、価値あるコンテンツを提供できます。

まとめ
そのまま設問を転載するのではなく、「引用」や「解説」をメインにした形で工夫するのが安全かつ有益です。もし具体的な例文や内容案が必要ならお手伝いします！

#...............................................................................
* データサイエンス100本ノック (構造化データ加工編)の全設問は github で無料公開されてるので、気にすることもない？

- 推奨されるブログ運営のアプローチ

問題文がGitHubで無料公開されているとしても、ブログ運営の際は次の方法が無難です：

リンクを活用： GitHubの該当リポジトリにリンクを貼り、「全設問は公式リポジトリから参照できます」と案内する。
自分の解説を中心に： 設問内容を参考にして、自分の言葉で解説を加えるか、手法や考え方のポイントをブログで紹介する。
独自の例題を作成： 書籍やGitHubの設問を参考に、類似するがオリジナルな設問を作成することで、独自性を高める。

#...............................................................................
* 下記のリポジトリREADMEに

https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess

「大学、企業など組織でのご利用にあたっては、「データサイエンティスト協会スキル定義委員」の「データサイエンス100本ノック（構造化データ加工編）」を利用していることを明示いただければ自由に利用してOK」

という記載があります。個人の場合はどうなの？
--
GitHubリポジトリのREADMEに記載されている内容を見る限り、以下のように解釈できます。

---

### **1. 「組織での利用」についての記載**
リポジトリに書かれている「大学、企業など組織でのご利用」についての条件は、**「データサイエンス100本ノック（構造化データ加工編）」を利用していることを明示すれば自由に利用できる**、というものです。この記述は明確に**組織利用**を対象としていますが、**個人利用**については具体的に触れられていません。

---

### **2. 個人利用についての解釈**
個人利用に関する明示的な制限や条件がないため、以下のように考えるのが合理的です：

- 個人で利用する場合も、組織利用と同様に「出典を明示すれば自由に利用可能」と解釈するのが自然です。  
- 出典の明示方法としては、例えばブログに以下のような形で記載すれば問題ないと考えられます：  
  「この問題は、データサイエンティスト協会スキル定義委員による『データサイエンス100本ノック（構造化データ加工編）』を元にしています。」  
  または、リポジトリへのリンクを追加する。

ただし、**商用利用（例えばアフィリエイトブログ）については慎重に判断**した方が良いです。商用利用について明記されていない場合、トラブルを避けるために以下を確認すると安心です：
- リポジトリ管理者（著者や協会）にメールやGitHubのIssueを使って問い合わせる。
- 商用利用についての具体的な記載がない場合でも、出典を明示した上で利用し、内容の大部分を転載せず解説を中心にする。

---

### **3. 出典を明示する際のポイント**
- **書籍名とリポジトリ名**を必ず記載する。
- リンクもあわせて掲載することで、公式の意図に沿った利用になります。

例：  
「この記事では、データサイエンティスト協会スキル定義委員が提供している『データサイエンス100本ノック（構造化データ加工編）』の問題を参考にしています。詳細はGitHubリポジトリ（[こちら](https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess)）をご覧ください。」

---

### **4. 個人利用と商用利用の線引き**
「自由に利用してOK」という記述がある場合でも、ブログでアフィリエイトリンクを掲載して収益化する場合、商用利用に該当すると判断される可能性があります。商用利用についてはREADMEで具体的に触れられていないため、念のため以下をおすすめします：
- GitHubのリポジトリ管理者に問い合わせて、アフィリエイトを含むブログでの利用について確認する。
- 問題文を直接転載せず、あくまで「解説」や「要約」「オリジナルな問題作成」を中心に構成する。

---

### **結論**
個人利用も自由に利用可能と解釈できますが、**出典の明示は必須**です。また、アフィリエイトブログなど商用利用に該当するケースでは、リポジトリ管理者に事前に確認を取るのが安全です。問題文をそのまま転載するのではなく、自分の解説や考察をメインにすることでトラブルを避けるとともに、よりオリジナルなコンテンツを提供できます。

#-------------------------------------------------------------------------------

